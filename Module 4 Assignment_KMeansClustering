# Step 3 K-Means Application Development

import pandas as pd

# Load dataset
df = pd.read_csv("C:\\Users\\HP\\Desktop\\Nexford University\\BAN6440- Applied Machine Learning\\Module 4 Assignment\\Mall_Customers.csv")

# Print the first 5 rows to inspect the data
print(df.head())

# Data Cleaning
# My dataset is clean, if not, I will use
# df.fillna(df.mean(), inplace=True) to fill the missing values with mean OR
# df.dropna(inplace=True) to drop rows with missing values

# Lets Feature Scaling and selection
# Making sure my features are numeric, by normalizing my data

import pandas as pd
from sklearn.preprocessing import StandardScaler, OneHotEncoder
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline

# Loading the dataset
data = pd.read_csv("C:\\Users\\HP\\Desktop\\Nexford University\\BAN6440- Applied Machine Learning\\Module 4 Assignment\\Mall_Customers.csv")  # Assuming your data is in CSV format

# Drop the CustomerID column
data = data.drop(columns=['CustomerID'])

# Setting up the preprocessing pipeline
preprocessor = ColumnTransformer(
    transformers=[
        ('num', StandardScaler(), ['Age', 'Annual Income (k$)', 'Spending Score (1-100)']),
        ('cat', OneHotEncoder(), ['Gender'])
    ])

# Apply transformations
processed_data = preprocessor.fit_transform(data)

# Convert the transformed data into a DataFrame
processed_df = pd.DataFrame(processed_data, columns=['Age', 'Annual Income (k$)', 'Spending Score (1-100)', 'Male', 'Female'])

# Display the first few rows of the processed data
print(processed_df.head())

# K-Means Clustering
# Applying the KMeans Algorithms

from sklearn.cluster import KMeans

# Apply K-Means (choose the number of clusters)
kmeans = KMeans(n_clusters=3, random_state=42)
kmeans.fit(processed_df)

# Get the cluster labels for each data point
df['Cluster'] = kmeans.labels_

# Display dataframe with cluster labels
print(df.head())

# Lets visualize the result using matplotlib

import matplotlib.pyplot as plt

plt.scatter(df['Age'], df['Annual Income (k$)'], c=df['Cluster'], cmap='viridis')
plt.xlabel('Age')
plt.ylabel('Annual Income (k$)')
plt.title('K-Means Clustering')
plt.show()

# Evaluating the cluster result
from sklearn.metrics import silhouette_score
score = silhouette_score(processed_df, kmeans.labels_)
print(f'Silhouette Score: {score}')


# Reference

# Data preprocessing and feature Scaling with StandardScaler was performed using Pandas and Scikit-learn libraries.
# ELbow method was used to determine the optimal number of clusters for the K-Means algorithms.
# The K-Means algorithms was implemented usin scikit-learn.

# Choudhary, V. (2018). Mall Customer Segmentation Data. Www.kaggle.com. https://www.kaggle.com/datasets/vjchoudhary7/customer-segmentation-tutorial-in-python
# greeshmitha. (2024, February 13). Best Python Data Structures for Statistical Computing. Analytics Insight. https://www.analyticsinsight.net/latest-news/best-python-data-structures-for-statistical-computing
# Scikit-learn. (2019). scikit-learn: machine learning in Python — scikit-learn 0.20.3 documentation. Scikit-Learn.org. https://scikit-learn.org/stable/index.html
# Thorndike, R. L. (1953). Who belongs in the Family?. Psychometrika (Vol. 18, pp. 267–276).
